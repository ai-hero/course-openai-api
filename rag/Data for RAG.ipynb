{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0d0cefd3-b657-408a-a01d-559b326d82df",
   "metadata": {},
   "source": [
    "# Generating Synthetic Data for Retrieval Augmented Generation. \n",
    "\n",
    "In this notebook, we'll generate a synthetic dataset for RAG using Wikipedia. We'll build on all documents in the topic San Francisco."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a657d0ad-3f9e-438e-97a8-16c44932d713",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: llama-index in /Users/rahulparundekar/workspaces/course-openai-api/venv/lib/python3.11/site-packages (0.9.39)\n",
      "Requirement already satisfied: wikipedia in /Users/rahulparundekar/workspaces/course-openai-api/venv/lib/python3.11/site-packages (1.4.0)\n",
      "Requirement already satisfied: tqdm in /Users/rahulparundekar/workspaces/course-openai-api/venv/lib/python3.11/site-packages (4.66.1)\n",
      "Requirement already satisfied: python-dotenv in /Users/rahulparundekar/workspaces/course-openai-api/venv/lib/python3.11/site-packages (1.0.1)\n",
      "Collecting spacy\n",
      "  Downloading spacy-3.7.2-cp311-cp311-macosx_10_9_x86_64.whl.metadata (25 kB)\n",
      "Requirement already satisfied: SQLAlchemy>=1.4.49 in /Users/rahulparundekar/workspaces/course-openai-api/venv/lib/python3.11/site-packages (from SQLAlchemy[asyncio]>=1.4.49->llama-index) (2.0.25)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.6 in /Users/rahulparundekar/workspaces/course-openai-api/venv/lib/python3.11/site-packages (from llama-index) (3.9.1)\n",
      "Requirement already satisfied: dataclasses-json in /Users/rahulparundekar/workspaces/course-openai-api/venv/lib/python3.11/site-packages (from llama-index) (0.6.3)\n",
      "Requirement already satisfied: deprecated>=1.2.9.3 in /Users/rahulparundekar/workspaces/course-openai-api/venv/lib/python3.11/site-packages (from llama-index) (1.2.14)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /Users/rahulparundekar/workspaces/course-openai-api/venv/lib/python3.11/site-packages (from llama-index) (2023.12.2)\n",
      "Requirement already satisfied: httpx in /Users/rahulparundekar/workspaces/course-openai-api/venv/lib/python3.11/site-packages (from llama-index) (0.26.0)\n",
      "Requirement already satisfied: nest-asyncio<2.0.0,>=1.5.8 in /Users/rahulparundekar/workspaces/course-openai-api/venv/lib/python3.11/site-packages (from llama-index) (1.6.0)\n",
      "Requirement already satisfied: networkx>=3.0 in /Users/rahulparundekar/workspaces/course-openai-api/venv/lib/python3.11/site-packages (from llama-index) (3.2.1)\n",
      "Requirement already satisfied: nltk<4.0.0,>=3.8.1 in /Users/rahulparundekar/workspaces/course-openai-api/venv/lib/python3.11/site-packages (from llama-index) (3.8.1)\n",
      "Requirement already satisfied: numpy in /Users/rahulparundekar/workspaces/course-openai-api/venv/lib/python3.11/site-packages (from llama-index) (1.26.3)\n",
      "Requirement already satisfied: openai>=1.1.0 in /Users/rahulparundekar/workspaces/course-openai-api/venv/lib/python3.11/site-packages (from llama-index) (1.10.0)\n",
      "Requirement already satisfied: pandas in /Users/rahulparundekar/workspaces/course-openai-api/venv/lib/python3.11/site-packages (from llama-index) (2.2.0)\n",
      "Requirement already satisfied: requests>=2.31.0 in /Users/rahulparundekar/workspaces/course-openai-api/venv/lib/python3.11/site-packages (from llama-index) (2.31.0)\n",
      "Requirement already satisfied: tenacity<9.0.0,>=8.2.0 in /Users/rahulparundekar/workspaces/course-openai-api/venv/lib/python3.11/site-packages (from llama-index) (8.2.3)\n",
      "Requirement already satisfied: tiktoken>=0.3.3 in /Users/rahulparundekar/workspaces/course-openai-api/venv/lib/python3.11/site-packages (from llama-index) (0.5.2)\n",
      "Requirement already satisfied: typing-extensions>=4.5.0 in /Users/rahulparundekar/workspaces/course-openai-api/venv/lib/python3.11/site-packages (from llama-index) (4.9.0)\n",
      "Requirement already satisfied: typing-inspect>=0.8.0 in /Users/rahulparundekar/workspaces/course-openai-api/venv/lib/python3.11/site-packages (from llama-index) (0.9.0)\n",
      "Requirement already satisfied: beautifulsoup4 in /Users/rahulparundekar/workspaces/course-openai-api/venv/lib/python3.11/site-packages (from wikipedia) (4.12.3)\n",
      "Collecting spacy-legacy<3.1.0,>=3.0.11 (from spacy)\n",
      "  Downloading spacy_legacy-3.0.12-py2.py3-none-any.whl (29 kB)\n",
      "Collecting spacy-loggers<2.0.0,>=1.0.0 (from spacy)\n",
      "  Downloading spacy_loggers-1.0.5-py3-none-any.whl.metadata (23 kB)\n",
      "Collecting murmurhash<1.1.0,>=0.28.0 (from spacy)\n",
      "  Downloading murmurhash-1.0.10-cp311-cp311-macosx_10_9_x86_64.whl.metadata (2.0 kB)\n",
      "Collecting cymem<2.1.0,>=2.0.2 (from spacy)\n",
      "  Downloading cymem-2.0.8-cp311-cp311-macosx_10_9_x86_64.whl.metadata (8.4 kB)\n",
      "Collecting preshed<3.1.0,>=3.0.2 (from spacy)\n",
      "  Downloading preshed-3.0.9-cp311-cp311-macosx_10_9_x86_64.whl.metadata (2.2 kB)\n",
      "Collecting thinc<8.3.0,>=8.1.8 (from spacy)\n",
      "  Downloading thinc-8.2.2-cp311-cp311-macosx_10_9_x86_64.whl.metadata (15 kB)\n",
      "Collecting wasabi<1.2.0,>=0.9.1 (from spacy)\n",
      "  Downloading wasabi-1.1.2-py3-none-any.whl.metadata (28 kB)\n",
      "Collecting srsly<3.0.0,>=2.4.3 (from spacy)\n",
      "  Downloading srsly-2.4.8-cp311-cp311-macosx_10_9_x86_64.whl.metadata (20 kB)\n",
      "Collecting catalogue<2.1.0,>=2.0.6 (from spacy)\n",
      "  Downloading catalogue-2.0.10-py3-none-any.whl.metadata (14 kB)\n",
      "Collecting weasel<0.4.0,>=0.1.0 (from spacy)\n",
      "  Downloading weasel-0.3.4-py3-none-any.whl.metadata (4.7 kB)\n",
      "Collecting typer<0.10.0,>=0.3.0 (from spacy)\n",
      "  Using cached typer-0.9.0-py3-none-any.whl (45 kB)\n",
      "Collecting smart-open<7.0.0,>=5.2.1 (from spacy)\n",
      "  Downloading smart_open-6.4.0-py3-none-any.whl.metadata (21 kB)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /Users/rahulparundekar/workspaces/course-openai-api/venv/lib/python3.11/site-packages (from spacy) (2.5.3)\n",
      "Collecting jinja2 (from spacy)\n",
      "  Downloading Jinja2-3.1.3-py3-none-any.whl.metadata (3.3 kB)\n",
      "Requirement already satisfied: setuptools in /Users/rahulparundekar/workspaces/course-openai-api/venv/lib/python3.11/site-packages (from spacy) (68.2.2)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/rahulparundekar/workspaces/course-openai-api/venv/lib/python3.11/site-packages (from spacy) (23.2)\n",
      "Collecting langcodes<4.0.0,>=3.2.0 (from spacy)\n",
      "  Using cached langcodes-3.3.0-py3-none-any.whl (181 kB)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /Users/rahulparundekar/workspaces/course-openai-api/venv/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index) (23.2.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /Users/rahulparundekar/workspaces/course-openai-api/venv/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index) (6.0.4)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /Users/rahulparundekar/workspaces/course-openai-api/venv/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index) (1.9.4)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /Users/rahulparundekar/workspaces/course-openai-api/venv/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index) (1.4.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /Users/rahulparundekar/workspaces/course-openai-api/venv/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index) (1.3.1)\n",
      "Requirement already satisfied: wrapt<2,>=1.10 in /Users/rahulparundekar/workspaces/course-openai-api/venv/lib/python3.11/site-packages (from deprecated>=1.2.9.3->llama-index) (1.16.0)\n",
      "Requirement already satisfied: click in /Users/rahulparundekar/workspaces/course-openai-api/venv/lib/python3.11/site-packages (from nltk<4.0.0,>=3.8.1->llama-index) (8.1.7)\n",
      "Requirement already satisfied: joblib in /Users/rahulparundekar/workspaces/course-openai-api/venv/lib/python3.11/site-packages (from nltk<4.0.0,>=3.8.1->llama-index) (1.3.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /Users/rahulparundekar/workspaces/course-openai-api/venv/lib/python3.11/site-packages (from nltk<4.0.0,>=3.8.1->llama-index) (2023.12.25)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /Users/rahulparundekar/workspaces/course-openai-api/venv/lib/python3.11/site-packages (from openai>=1.1.0->llama-index) (4.2.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /Users/rahulparundekar/workspaces/course-openai-api/venv/lib/python3.11/site-packages (from openai>=1.1.0->llama-index) (1.9.0)\n",
      "Requirement already satisfied: sniffio in /Users/rahulparundekar/workspaces/course-openai-api/venv/lib/python3.11/site-packages (from openai>=1.1.0->llama-index) (1.3.0)\n",
      "Requirement already satisfied: certifi in /Users/rahulparundekar/workspaces/course-openai-api/venv/lib/python3.11/site-packages (from httpx->llama-index) (2023.11.17)\n",
      "Requirement already satisfied: httpcore==1.* in /Users/rahulparundekar/workspaces/course-openai-api/venv/lib/python3.11/site-packages (from httpx->llama-index) (1.0.2)\n",
      "Requirement already satisfied: idna in /Users/rahulparundekar/workspaces/course-openai-api/venv/lib/python3.11/site-packages (from httpx->llama-index) (3.6)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /Users/rahulparundekar/workspaces/course-openai-api/venv/lib/python3.11/site-packages (from httpcore==1.*->httpx->llama-index) (0.14.0)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /Users/rahulparundekar/workspaces/course-openai-api/venv/lib/python3.11/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.14.6 in /Users/rahulparundekar/workspaces/course-openai-api/venv/lib/python3.11/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (2.14.6)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/rahulparundekar/workspaces/course-openai-api/venv/lib/python3.11/site-packages (from requests>=2.31.0->llama-index) (3.3.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/rahulparundekar/workspaces/course-openai-api/venv/lib/python3.11/site-packages (from requests>=2.31.0->llama-index) (2.1.0)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /Users/rahulparundekar/workspaces/course-openai-api/venv/lib/python3.11/site-packages (from SQLAlchemy>=1.4.49->SQLAlchemy[asyncio]>=1.4.49->llama-index) (3.0.3)\n",
      "Collecting blis<0.8.0,>=0.7.8 (from thinc<8.3.0,>=8.1.8->spacy)\n",
      "  Downloading blis-0.7.11-cp311-cp311-macosx_10_9_x86_64.whl.metadata (7.4 kB)\n",
      "Collecting confection<1.0.0,>=0.0.1 (from thinc<8.3.0,>=8.1.8->spacy)\n",
      "  Downloading confection-0.1.4-py3-none-any.whl.metadata (19 kB)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in /Users/rahulparundekar/workspaces/course-openai-api/venv/lib/python3.11/site-packages (from typing-inspect>=0.8.0->llama-index) (1.0.0)\n",
      "Collecting cloudpathlib<0.17.0,>=0.7.0 (from weasel<0.4.0,>=0.1.0->spacy)\n",
      "  Downloading cloudpathlib-0.16.0-py3-none-any.whl.metadata (14 kB)\n",
      "Requirement already satisfied: soupsieve>1.2 in /Users/rahulparundekar/workspaces/course-openai-api/venv/lib/python3.11/site-packages (from beautifulsoup4->wikipedia) (2.5)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /Users/rahulparundekar/workspaces/course-openai-api/venv/lib/python3.11/site-packages (from dataclasses-json->llama-index) (3.20.2)\n",
      "Collecting MarkupSafe>=2.0 (from jinja2->spacy)\n",
      "  Downloading MarkupSafe-2.1.4-cp311-cp311-macosx_10_9_x86_64.whl.metadata (3.0 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/rahulparundekar/workspaces/course-openai-api/venv/lib/python3.11/site-packages (from pandas->llama-index) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/rahulparundekar/workspaces/course-openai-api/venv/lib/python3.11/site-packages (from pandas->llama-index) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /Users/rahulparundekar/workspaces/course-openai-api/venv/lib/python3.11/site-packages (from pandas->llama-index) (2023.4)\n",
      "Requirement already satisfied: six>=1.5 in /Users/rahulparundekar/workspaces/course-openai-api/venv/lib/python3.11/site-packages (from python-dateutil>=2.8.2->pandas->llama-index) (1.16.0)\n",
      "Downloading spacy-3.7.2-cp311-cp311-macosx_10_9_x86_64.whl (6.7 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.7/6.7 MB\u001b[0m \u001b[31m10.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading catalogue-2.0.10-py3-none-any.whl (17 kB)\n",
      "Downloading cymem-2.0.8-cp311-cp311-macosx_10_9_x86_64.whl (41 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.9/41.9 kB\u001b[0m \u001b[31m683.9 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading murmurhash-1.0.10-cp311-cp311-macosx_10_9_x86_64.whl (26 kB)\n",
      "Downloading preshed-3.0.9-cp311-cp311-macosx_10_9_x86_64.whl (132 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m133.0/133.0 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading smart_open-6.4.0-py3-none-any.whl (57 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.0/57.0 kB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading spacy_loggers-1.0.5-py3-none-any.whl (22 kB)\n",
      "Downloading srsly-2.4.8-cp311-cp311-macosx_10_9_x86_64.whl (490 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m490.0/490.0 kB\u001b[0m \u001b[31m9.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading thinc-8.2.2-cp311-cp311-macosx_10_9_x86_64.whl (861 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m861.5/861.5 kB\u001b[0m \u001b[31m11.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m0:01\u001b[0m\n",
      "\u001b[?25hDownloading wasabi-1.1.2-py3-none-any.whl (27 kB)\n",
      "Downloading weasel-0.3.4-py3-none-any.whl (50 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.1/50.1 kB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading Jinja2-3.1.3-py3-none-any.whl (133 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m133.2/133.2 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading blis-0.7.11-cp311-cp311-macosx_10_9_x86_64.whl (6.1 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.1/6.1 MB\u001b[0m \u001b[31m11.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m0:01\u001b[0m:01\u001b[0m\n",
      "\u001b[?25hDownloading cloudpathlib-0.16.0-py3-none-any.whl (45 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.0/45.0 kB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading confection-0.1.4-py3-none-any.whl (35 kB)\n",
      "Downloading MarkupSafe-2.1.4-cp311-cp311-macosx_10_9_x86_64.whl (13 kB)\n",
      "Installing collected packages: cymem, wasabi, typer, spacy-loggers, spacy-legacy, smart-open, murmurhash, MarkupSafe, langcodes, cloudpathlib, catalogue, blis, srsly, preshed, jinja2, confection, weasel, thinc, spacy\n",
      "Successfully installed MarkupSafe-2.1.4 blis-0.7.11 catalogue-2.0.10 cloudpathlib-0.16.0 confection-0.1.4 cymem-2.0.8 jinja2-3.1.3 langcodes-3.3.0 murmurhash-1.0.10 preshed-3.0.9 smart-open-6.4.0 spacy-3.7.2 spacy-legacy-3.0.12 spacy-loggers-1.0.5 srsly-2.4.8 thinc-8.2.2 typer-0.9.0 wasabi-1.1.2 weasel-0.3.4\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.3.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install llama-index wikipedia tqdm python-dotenv spacy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "758997ce-54bb-491d-b018-3a56c9dc08ab",
   "metadata": {},
   "source": [
    "## Setup Environment Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "93000784-1a38-486d-824c-12e2bbde3bc0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a20f4bf-89bb-401c-a835-a6d454242482",
   "metadata": {},
   "source": [
    "## Save Articles from Wikipedia\n",
    "\n",
    "We'll first download data from Wikipedia pages about popular cities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d3f594c4-3770-45e4-b6b1-2587709763b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "popular_cities = [\"San Francisco\", \"Oakland, California\", \"San Jose, California\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ef804b86-55a3-423b-b8a0-6214a2adc7ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import wikipedia\n",
    "\n",
    "# Create a directory to store the content\n",
    "documents_folder = os.path.join(os.path.abspath(\"\"), \".content\")\n",
    "os.makedirs(documents_folder, exist_ok=True)\n",
    "\n",
    "\n",
    "# Function to save article content to a file\n",
    "def save_article_content(city, folder):\n",
    "    try:\n",
    "        # Fetching the content of the city's Wikipedia page\n",
    "        content = wikipedia.page(city).content\n",
    "        file_path = os.path.join(folder, city.replace(\" \", \"_\") + \".txt\")\n",
    "        with open(file_path, \"w\") as file:\n",
    "            file.write(content)\n",
    "        return file_path\n",
    "    except Exception as e:\n",
    "        return str(e)\n",
    "\n",
    "\n",
    "# Saving the content of each city to the folder\n",
    "saved_files = [save_article_content(city, documents_folder) for city in popular_cities]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e7f0e5d-6824-43f3-aebc-4a855245b1f9",
   "metadata": {},
   "source": [
    "## Generate Synthetic RAG Data From the Documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7805cc42-ab01-44e4-9a13-398250bea39b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We'll load data about the histories of some cities from Wikipedia.\n",
    "from llama_index import ServiceContext, VectorStoreIndex\n",
    "from llama_index.readers import WikipediaReader\n",
    "\n",
    "documents = WikipediaReader().load_data(pages=[f\"History of {x}\" for x in popular_cities])\n",
    "service_context = ServiceContext.from_defaults(chunk_size=512, chunk_overlap=50)\n",
    "index = VectorStoreIndex.from_documents(documents, service_context=service_context)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2771da43-eae8-4ebc-a7cb-749ff0275309",
   "metadata": {},
   "source": [
    "### Generate RAG Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "56d1254b-5026-438f-998e-cb9bf7e503dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f1ef7b0e50774b2f884f8a9f51fb35d8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Parsing nodes:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# generate questions against chunks\n",
    "from llama_index import ServiceContext\n",
    "from llama_index.llama_dataset.generator import RagDatasetGenerator\n",
    "from llama_index.llms import OpenAI\n",
    "\n",
    "# set context for llm provider\n",
    "gpt_context = ServiceContext.from_defaults(llm=OpenAI(model=\"gpt-4\", temperature=0.3))\n",
    "\n",
    "# instantiate a DatasetGenerator\n",
    "dataset_generator = RagDatasetGenerator.from_documents(\n",
    "    documents,\n",
    "    service_context=gpt_context,\n",
    "    num_questions_per_chunk=1,  # set the number of questions per nodes\n",
    "    show_progress=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6029df6a-2f27-41a6-a1ed-c0bd22518bb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 29/29 [00:09<00:00,  2.93it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:18<00:00, 18.69s/it]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:18<00:00, 18.51s/it]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:27<00:00, 27.51s/it]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:29<00:00, 29.90s/it]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:21<00:00, 21.90s/it]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:06<00:00,  6.67s/it]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:14<00:00, 14.61s/it]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:21<00:00, 21.12s/it]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:08<00:00,  8.07s/it]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:13<00:00, 13.72s/it]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10/10 [00:05<00:00,  1.88it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:02<00:00,  2.14s/it]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:02<00:00,  2.25s/it]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:10<00:00, 10.78s/it]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:11<00:00, 11.99s/it]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10/10 [00:07<00:00,  1.42it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:20<00:00, 20.09s/it]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:22<00:00, 22.16s/it]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:17<00:00, 17.24s/it]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:15<00:00, 15.51s/it]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:12<00:00, 12.19s/it]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:17<00:00, 17.86s/it]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:06<00:00,  6.62s/it]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:17<00:00, 17.17s/it]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:05<00:00,  5.12s/it]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:03<00:00,  3.62s/it]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:20<00:00, 20.88s/it]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:19<00:00, 19.96s/it]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:03<00:00,  3.25s/it]\n"
     ]
    }
   ],
   "source": [
    "import nest_asyncio\n",
    "\n",
    "nest_asyncio.apply()\n",
    "rag_dataset = dataset_generator.generate_dataset_from_nodes()\n",
    "df = rag_dataset.to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "eaf21c0e-8489-4094-8800-f14c2f25492b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>query</th>\n",
       "      <th>reference_contexts</th>\n",
       "      <th>reference_answer</th>\n",
       "      <th>reference_answer_by</th>\n",
       "      <th>query_by</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Discuss the early history of San Francisco, in...</td>\n",
       "      <td>[The history of the city of San Francisco, Cal...</td>\n",
       "      <td>The earliest evidence of human habitation in S...</td>\n",
       "      <td>ai (gpt-4)</td>\n",
       "      <td>ai (gpt-4)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Discuss the early European exploration and set...</td>\n",
       "      <td>[== Arrival of Europeans and early settlement ...</td>\n",
       "      <td>The first documented European sighting of San ...</td>\n",
       "      <td>ai (gpt-4)</td>\n",
       "      <td>ai (gpt-4)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Discuss the impact of the 1848 California gold...</td>\n",
       "      <td>[== 1848 gold rush ==\\nThe California gold rus...</td>\n",
       "      <td>The 1848 California gold rush had a significan...</td>\n",
       "      <td>ai (gpt-4)</td>\n",
       "      <td>ai (gpt-4)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Discuss the transformation of San Francisco in...</td>\n",
       "      <td>[== Paris of the West ==\\n\\nIt was during the ...</td>\n",
       "      <td>San Francisco began to transform into a major ...</td>\n",
       "      <td>ai (gpt-4)</td>\n",
       "      <td>ai (gpt-4)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Discuss the corruption and graft trials involv...</td>\n",
       "      <td>[== Corruption and graft trials ==\\n\\nMayor Eu...</td>\n",
       "      <td>Mayor Eugene Schmitz, president of the Musicia...</td>\n",
       "      <td>ai (gpt-4)</td>\n",
       "      <td>ai (gpt-4)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               query  \\\n",
       "0  Discuss the early history of San Francisco, in...   \n",
       "1  Discuss the early European exploration and set...   \n",
       "2  Discuss the impact of the 1848 California gold...   \n",
       "3  Discuss the transformation of San Francisco in...   \n",
       "4  Discuss the corruption and graft trials involv...   \n",
       "\n",
       "                                  reference_contexts  \\\n",
       "0  [The history of the city of San Francisco, Cal...   \n",
       "1  [== Arrival of Europeans and early settlement ...   \n",
       "2  [== 1848 gold rush ==\\nThe California gold rus...   \n",
       "3  [== Paris of the West ==\\n\\nIt was during the ...   \n",
       "4  [== Corruption and graft trials ==\\n\\nMayor Eu...   \n",
       "\n",
       "                                    reference_answer reference_answer_by  \\\n",
       "0  The earliest evidence of human habitation in S...          ai (gpt-4)   \n",
       "1  The first documented European sighting of San ...          ai (gpt-4)   \n",
       "2  The 1848 California gold rush had a significan...          ai (gpt-4)   \n",
       "3  San Francisco began to transform into a major ...          ai (gpt-4)   \n",
       "4  Mayor Eugene Schmitz, president of the Musicia...          ai (gpt-4)   \n",
       "\n",
       "     query_by  \n",
       "0  ai (gpt-4)  \n",
       "1  ai (gpt-4)  \n",
       "2  ai (gpt-4)  \n",
       "3  ai (gpt-4)  \n",
       "4  ai (gpt-4)  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d34685b2-4fc9-4fa3-ade4-a93fc9227aa9",
   "metadata": {},
   "source": [
    "### Save the Dataset in HuggingFace format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "13242385-0137-4e05-88cc-25ae79478567",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset contains 47 rows\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7a05d21b112a497e96ab99e1c458ae86",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/47 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from datasets import Dataset\n",
    "\n",
    "dataset = Dataset.from_pandas(df)\n",
    "print(f\"Dataset contains {len(dataset)} rows\")\n",
    "dataset.save_to_disk(\"rag_synth_data.hf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14f0bfcd-44f1-484e-984a-8015e1781f3e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
