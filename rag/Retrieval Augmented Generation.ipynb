{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5cf205f5-2483-4b65-b655-ad06f1253d7b",
   "metadata": {},
   "source": [
    "# Retrieval Augmented Generation\n",
    "This notebook provides an introduction to Retrieval Augmented Generation. Especially, we will learn how to improve our RAG based on different embeddings, LLMs, etc.\n",
    "\n",
    "The focus here is the methodology of how to improve your Rag using a nort-star metric (e.g. Ragas Score). Your actual use case might be different, and the best chunking, prompt, embedding, retrieval strategy, and LLM for it might be different. Use this methodology to pick the best one for your use case."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd50c39d-3c47-4f34-88c2-84bbc54d020f",
   "metadata": {},
   "source": [
    "For this tutorial, we'll use LlamaIndex, which provides some abstractions over underlying APIs used for building LLM applications. For more about RAG and LlamaIndex's definitions, see [here](https://docs.llamaindex.ai/en/stable/getting_started/concepts.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bb47e7fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Ignoring invalid distribution ~ip (/Users/rahulparundekar/workspaces/course-openai-api/venv/lib/python3.11/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution ~ip (/Users/rahulparundekar/workspaces/course-openai-api/venv/lib/python3.11/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0mRequirement already satisfied: ragas==0.0.22 in /Users/rahulparundekar/workspaces/course-openai-api/venv/lib/python3.11/site-packages (0.0.22)\n",
      "Requirement already satisfied: numpy in /Users/rahulparundekar/workspaces/course-openai-api/venv/lib/python3.11/site-packages (from ragas==0.0.22) (1.26.4)\n",
      "Requirement already satisfied: datasets in /Users/rahulparundekar/workspaces/course-openai-api/venv/lib/python3.11/site-packages (from ragas==0.0.22) (2.17.1)\n",
      "Requirement already satisfied: tiktoken in /Users/rahulparundekar/workspaces/course-openai-api/venv/lib/python3.11/site-packages (from ragas==0.0.22) (0.6.0)\n",
      "Requirement already satisfied: langchain in /Users/rahulparundekar/workspaces/course-openai-api/venv/lib/python3.11/site-packages (from ragas==0.0.22) (0.1.8)\n",
      "Requirement already satisfied: openai>1 in /Users/rahulparundekar/workspaces/course-openai-api/venv/lib/python3.11/site-packages (from ragas==0.0.22) (1.12.0)\n",
      "Requirement already satisfied: pysbd>=0.3.4 in /Users/rahulparundekar/workspaces/course-openai-api/venv/lib/python3.11/site-packages (from ragas==0.0.22) (0.3.4)\n",
      "Requirement already satisfied: nest-asyncio in /Users/rahulparundekar/workspaces/course-openai-api/venv/lib/python3.11/site-packages (from ragas==0.0.22) (1.6.0)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /Users/rahulparundekar/workspaces/course-openai-api/venv/lib/python3.11/site-packages (from openai>1->ragas==0.0.22) (4.3.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /Users/rahulparundekar/workspaces/course-openai-api/venv/lib/python3.11/site-packages (from openai>1->ragas==0.0.22) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /Users/rahulparundekar/workspaces/course-openai-api/venv/lib/python3.11/site-packages (from openai>1->ragas==0.0.22) (0.26.0)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in /Users/rahulparundekar/workspaces/course-openai-api/venv/lib/python3.11/site-packages (from openai>1->ragas==0.0.22) (2.6.1)\n",
      "Requirement already satisfied: sniffio in /Users/rahulparundekar/workspaces/course-openai-api/venv/lib/python3.11/site-packages (from openai>1->ragas==0.0.22) (1.3.0)\n",
      "Requirement already satisfied: tqdm>4 in /Users/rahulparundekar/workspaces/course-openai-api/venv/lib/python3.11/site-packages (from openai>1->ragas==0.0.22) (4.66.2)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.7 in /Users/rahulparundekar/workspaces/course-openai-api/venv/lib/python3.11/site-packages (from openai>1->ragas==0.0.22) (4.9.0)\n",
      "Requirement already satisfied: filelock in /Users/rahulparundekar/workspaces/course-openai-api/venv/lib/python3.11/site-packages (from datasets->ragas==0.0.22) (3.13.1)\n",
      "Requirement already satisfied: pyarrow>=12.0.0 in /Users/rahulparundekar/workspaces/course-openai-api/venv/lib/python3.11/site-packages (from datasets->ragas==0.0.22) (15.0.0)\n",
      "Requirement already satisfied: pyarrow-hotfix in /Users/rahulparundekar/workspaces/course-openai-api/venv/lib/python3.11/site-packages (from datasets->ragas==0.0.22) (0.6)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /Users/rahulparundekar/workspaces/course-openai-api/venv/lib/python3.11/site-packages (from datasets->ragas==0.0.22) (0.3.8)\n",
      "Requirement already satisfied: pandas in /Users/rahulparundekar/workspaces/course-openai-api/venv/lib/python3.11/site-packages (from datasets->ragas==0.0.22) (2.2.0)\n",
      "Requirement already satisfied: requests>=2.19.0 in /Users/rahulparundekar/workspaces/course-openai-api/venv/lib/python3.11/site-packages (from datasets->ragas==0.0.22) (2.31.0)\n",
      "Requirement already satisfied: xxhash in /Users/rahulparundekar/workspaces/course-openai-api/venv/lib/python3.11/site-packages (from datasets->ragas==0.0.22) (3.4.1)\n",
      "Requirement already satisfied: multiprocess in /Users/rahulparundekar/workspaces/course-openai-api/venv/lib/python3.11/site-packages (from datasets->ragas==0.0.22) (0.70.16)\n",
      "Requirement already satisfied: fsspec<=2023.10.0,>=2023.1.0 in /Users/rahulparundekar/workspaces/course-openai-api/venv/lib/python3.11/site-packages (from fsspec[http]<=2023.10.0,>=2023.1.0->datasets->ragas==0.0.22) (2023.10.0)\n",
      "Requirement already satisfied: aiohttp in /Users/rahulparundekar/workspaces/course-openai-api/venv/lib/python3.11/site-packages (from datasets->ragas==0.0.22) (3.9.3)\n",
      "Requirement already satisfied: huggingface-hub>=0.19.4 in /Users/rahulparundekar/workspaces/course-openai-api/venv/lib/python3.11/site-packages (from datasets->ragas==0.0.22) (0.20.3)\n",
      "Requirement already satisfied: packaging in /Users/rahulparundekar/workspaces/course-openai-api/venv/lib/python3.11/site-packages (from datasets->ragas==0.0.22) (23.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Users/rahulparundekar/workspaces/course-openai-api/venv/lib/python3.11/site-packages (from datasets->ragas==0.0.22) (6.0.1)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /Users/rahulparundekar/workspaces/course-openai-api/venv/lib/python3.11/site-packages (from langchain->ragas==0.0.22) (2.0.27)\n",
      "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /Users/rahulparundekar/workspaces/course-openai-api/venv/lib/python3.11/site-packages (from langchain->ragas==0.0.22) (0.6.4)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /Users/rahulparundekar/workspaces/course-openai-api/venv/lib/python3.11/site-packages (from langchain->ragas==0.0.22) (1.33)\n",
      "Requirement already satisfied: langchain-community<0.1,>=0.0.21 in /Users/rahulparundekar/workspaces/course-openai-api/venv/lib/python3.11/site-packages (from langchain->ragas==0.0.22) (0.0.21)\n",
      "Requirement already satisfied: langchain-core<0.2,>=0.1.24 in /Users/rahulparundekar/workspaces/course-openai-api/venv/lib/python3.11/site-packages (from langchain->ragas==0.0.22) (0.1.24)\n",
      "Requirement already satisfied: langsmith<0.2.0,>=0.1.0 in /Users/rahulparundekar/workspaces/course-openai-api/venv/lib/python3.11/site-packages (from langchain->ragas==0.0.22) (0.1.2)\n",
      "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /Users/rahulparundekar/workspaces/course-openai-api/venv/lib/python3.11/site-packages (from langchain->ragas==0.0.22) (8.2.3)\n",
      "Requirement already satisfied: regex>=2022.1.18 in /Users/rahulparundekar/workspaces/course-openai-api/venv/lib/python3.11/site-packages (from tiktoken->ragas==0.0.22) (2023.12.25)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /Users/rahulparundekar/workspaces/course-openai-api/venv/lib/python3.11/site-packages (from aiohttp->datasets->ragas==0.0.22) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /Users/rahulparundekar/workspaces/course-openai-api/venv/lib/python3.11/site-packages (from aiohttp->datasets->ragas==0.0.22) (23.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /Users/rahulparundekar/workspaces/course-openai-api/venv/lib/python3.11/site-packages (from aiohttp->datasets->ragas==0.0.22) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /Users/rahulparundekar/workspaces/course-openai-api/venv/lib/python3.11/site-packages (from aiohttp->datasets->ragas==0.0.22) (6.0.5)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /Users/rahulparundekar/workspaces/course-openai-api/venv/lib/python3.11/site-packages (from aiohttp->datasets->ragas==0.0.22) (1.9.4)\n",
      "Requirement already satisfied: idna>=2.8 in /Users/rahulparundekar/workspaces/course-openai-api/venv/lib/python3.11/site-packages (from anyio<5,>=3.5.0->openai>1->ragas==0.0.22) (3.6)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /Users/rahulparundekar/workspaces/course-openai-api/venv/lib/python3.11/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain->ragas==0.0.22) (3.20.2)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /Users/rahulparundekar/workspaces/course-openai-api/venv/lib/python3.11/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain->ragas==0.0.22) (0.9.0)\n",
      "Requirement already satisfied: certifi in /Users/rahulparundekar/workspaces/course-openai-api/venv/lib/python3.11/site-packages (from httpx<1,>=0.23.0->openai>1->ragas==0.0.22) (2024.2.2)\n",
      "Requirement already satisfied: httpcore==1.* in /Users/rahulparundekar/workspaces/course-openai-api/venv/lib/python3.11/site-packages (from httpx<1,>=0.23.0->openai>1->ragas==0.0.22) (1.0.3)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /Users/rahulparundekar/workspaces/course-openai-api/venv/lib/python3.11/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai>1->ragas==0.0.22) (0.14.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /Users/rahulparundekar/workspaces/course-openai-api/venv/lib/python3.11/site-packages (from jsonpatch<2.0,>=1.33->langchain->ragas==0.0.22) (2.4)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /Users/rahulparundekar/workspaces/course-openai-api/venv/lib/python3.11/site-packages (from pydantic<3,>=1.9.0->openai>1->ragas==0.0.22) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.16.2 in /Users/rahulparundekar/workspaces/course-openai-api/venv/lib/python3.11/site-packages (from pydantic<3,>=1.9.0->openai>1->ragas==0.0.22) (2.16.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/rahulparundekar/workspaces/course-openai-api/venv/lib/python3.11/site-packages (from requests>=2.19.0->datasets->ragas==0.0.22) (3.3.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/rahulparundekar/workspaces/course-openai-api/venv/lib/python3.11/site-packages (from requests>=2.19.0->datasets->ragas==0.0.22) (2.2.1)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /Users/rahulparundekar/workspaces/course-openai-api/venv/lib/python3.11/site-packages (from SQLAlchemy<3,>=1.4->langchain->ragas==0.0.22) (3.0.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/rahulparundekar/workspaces/course-openai-api/venv/lib/python3.11/site-packages (from pandas->datasets->ragas==0.0.22) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/rahulparundekar/workspaces/course-openai-api/venv/lib/python3.11/site-packages (from pandas->datasets->ragas==0.0.22) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /Users/rahulparundekar/workspaces/course-openai-api/venv/lib/python3.11/site-packages (from pandas->datasets->ragas==0.0.22) (2024.1)\n",
      "Requirement already satisfied: six>=1.5 in /Users/rahulparundekar/workspaces/course-openai-api/venv/lib/python3.11/site-packages (from python-dateutil>=2.8.2->pandas->datasets->ragas==0.0.22) (1.16.0)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in /Users/rahulparundekar/workspaces/course-openai-api/venv/lib/python3.11/site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain->ragas==0.0.22) (1.0.0)\n",
      "\u001b[33mWARNING: Ignoring invalid distribution ~ip (/Users/rahulparundekar/workspaces/course-openai-api/venv/lib/python3.11/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution ~ip (/Users/rahulparundekar/workspaces/course-openai-api/venv/lib/python3.11/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution ~ip (/Users/rahulparundekar/workspaces/course-openai-api/venv/lib/python3.11/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install ragas==0.0.22"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4d49e8f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.0.22'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import ragas\n",
    "\n",
    "ragas.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "423cc82b-5f5c-4757-98b4-914a3ccad7d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset contains 3 rows\n",
      "100 files in folder: /Users/rahulparundekar/workspaces/course-openai-api/rag/.content/docs/1e41916248531ab7c35d0c9895b9e097.txt, ...\n"
     ]
    }
   ],
   "source": [
    "import hashlib\n",
    "import os\n",
    "from glob import glob\n",
    "\n",
    "from datasets import DatasetDict\n",
    "\n",
    "# Create a directory to store the content\n",
    "content_folder = os.path.join(os.path.abspath(\"\"), \".content/\")\n",
    "documents_folder = os.path.join(os.path.abspath(\"\"), \".content/docs/\")\n",
    "os.makedirs(documents_folder, exist_ok=True)\n",
    "\n",
    "NUM_DOCUMENTS = 100\n",
    "\n",
    "\n",
    "# Function to save article content to a file\n",
    "def save_article_content(text, folder):\n",
    "    try:\n",
    "        # Fetching the content of the city's Wikipedia page\n",
    "        checksum = hashlib.md5(text.encode(\"utf-8\")).hexdigest()\n",
    "        file_path = os.path.join(folder, checksum + \".txt\")\n",
    "        with open(file_path, \"w\") as file:\n",
    "            file.write(text)\n",
    "        return file_path\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        return str(e)\n",
    "\n",
    "\n",
    "dataset = DatasetDict.load_from_disk(f\"{content_folder}/rag_sciq_data.hf\")\n",
    "print(f\"Dataset contains {len(dataset)} rows\")\n",
    "\n",
    "# Saving the content of each train set document in a file\n",
    "saved_files = []\n",
    "for row in dataset[\"train\"]:\n",
    "    if row[\"support\"]:\n",
    "        saved_files.append(save_article_content(row[\"support\"], documents_folder))\n",
    "    if NUM_DOCUMENTS and len(saved_files) >= NUM_DOCUMENTS:\n",
    "        break\n",
    "# We'll load documents that we've already downloaded in the Synthetic Dataset for RAG\n",
    "data_dir = os.path.join(os.path.abspath(\"\"), \".content/docs\")\n",
    "input_files = glob(os.path.join(data_dir, \"*.txt\"))\n",
    "print(f\"{len(input_files)} files in folder: {input_files[0]}, ...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "927087f9-9b52-4a92-8fea-5422b1172922",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53f115d5-00b0-4f8c-85e6-4d4654d3ac43",
   "metadata": {},
   "source": [
    "## A simple RAG with LlamaIndex (using defaults)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "64847c2d-83e9-4ac6-bac5-102d6864ceb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index import ServiceContext, SimpleDirectoryReader, VectorStoreIndex\n",
    "from llama_index.llms import OpenAI"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "008b2089-5a78-42e7-aa87-5dd9b860d260",
   "metadata": {},
   "source": [
    "First, build the index from all the documents we have. Using default chunking, and embedding strategies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "01567917-d39e-4185-bc97-e2027df1c084",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading files: 100%|██████████| 100/100 [00:00<00:00, 3183.80file/s]\n"
     ]
    }
   ],
   "source": [
    "service_context = ServiceContext.from_defaults(llm=OpenAI())\n",
    "documents = SimpleDirectoryReader(input_files=input_files).load_data(\"*.txt\")\n",
    "index = VectorStoreIndex.from_documents(documents, service_context=service_context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4afe279f-b069-4135-8dd0-058d09f75e56",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_engine = index.as_query_engine()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b2432d76-a5a9-4637-b682-871847d28c51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question:\n",
      "What secures together immovable joints and prevents them from moving?\n",
      "\n",
      "Answer:\n",
      "Dense collagen secures together immovable joints and prevents them from moving.\n",
      "\n",
      "Expected Answer:\n",
      "Dense Collagen\n"
     ]
    }
   ],
   "source": [
    "from random import randint\n",
    "\n",
    "example_one = randint(0, len(input_files))\n",
    "question = dataset[\"train\"][example_one][\"question\"]\n",
    "expected_answer = dataset[\"train\"][example_one][\"answer\"]\n",
    "\n",
    "response = query_engine.query(question)\n",
    "print(\"Question:\")\n",
    "print(question)\n",
    "print(\"\\nAnswer:\")\n",
    "print(str(response))\n",
    "print(\"\\nExpected Answer:\")\n",
    "print(expected_answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "710cb97e-c7ad-4e31-aa42-097b956da4cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question:\n",
      "Which cycle tracks the flow of nitrogen through an ecosystem?\n",
      "\n",
      "Answer:\n",
      "The nitrogen cycle tracks the flow of nitrogen through an ecosystem.\n",
      "\n",
      "Expected Answer:\n",
      "Nitrogen Cycle\n"
     ]
    }
   ],
   "source": [
    "example_two = randint(0, len(input_files))\n",
    "question = dataset[\"train\"][example_two][\"question\"]\n",
    "expected_answer = dataset[\"train\"][example_two][\"answer\"]\n",
    "\n",
    "response = query_engine.query(question)\n",
    "print(\"Question:\")\n",
    "print(question)\n",
    "print(\"\\nAnswer:\")\n",
    "print(str(response))\n",
    "print(\"\\nExpected Answer:\")\n",
    "print(expected_answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0340c103-b046-4ef5-b605-28795829300f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question:\n",
      "Cutting down on the use of chemical fertilizers and preserving wetlands are ways to prevent what \"unlivable\" regions in bodies of water?\n",
      "\n",
      "Chunks:\n",
      "--------------------------\n",
      "Cutting down on the use of chemical fertilizers is one way to prevent dead zones in bodies of water. Preserving wetlands is also important. Wetlands are habitats such as swamps, marshes, and bogs where the ground is soggy or covered with water much of the year. Wetlands slow down and filter runoff before it reaches bodies of water. Wetlands also provide breeding grounds for many different species of organisms.\n",
      "--------------------------\n",
      "--------------------------\n",
      "Some animals change their depth by changing their density. Recall that things that are denser than their surroundings sink while those that are less dense than their surroundings float. Most fish have a swim bladder, a special sac that is filled with gases from their blood. When the fish's swim bladder is full, it is less dense than the surrounding water and the fish will rise towards the surface. Another property of water that affects lakes is the unique changes in density during phase changes. The density of most substances increases when a liquid becomes a solid. This is not so for water: Solid water is actually less dense than liquid water. It is for this reason that ice floats. Can you imagine a world where ice sank? Lakes would freeze from the bottom up, killing many fish. Frozen water in the Polar Regions would sink and change the ocean levels. The fact that ice floats is essential for the survival of many aquatic ecosystems and ultimately life on Earth. Besides the changes in density, there are other ways in which the phase changes of water have significant impacts. When water is trapped in small cracks in rocks, it will expand as it freezes and break up the rock causing weathering. The transpiration (evaporation) of water from a good-sized tree can move 1800 liters of water out of the ground in a single day. Sublimation, the phase change between solid and gas, is responsible for the formation of frost. As you can see, water has many special properties that make its role in nature unique. It is considered the \"universal solvent” because its bipolar molecule enables it to dissolve a wide variety of substances. Water is the only substance that occurs naturally in all three states; solid, liquid, and gas. Water is truly a miracle for life!.\n",
      "--------------------------\n",
      "\n",
      "Answer:\n",
      "prevent dead zones in bodies of water\n",
      "\n",
      "Expected Answer:\n",
      "Dead Zones\n"
     ]
    }
   ],
   "source": [
    "example_three = randint(0, len(input_files))\n",
    "question = dataset[\"train\"][example_three][\"question\"]\n",
    "expected_answer = dataset[\"train\"][example_three][\"answer\"]\n",
    "\n",
    "response = query_engine.query(question)\n",
    "print(\"Question:\")\n",
    "print(question)\n",
    "print(\"\\nChunks:\")\n",
    "for node in response.source_nodes:\n",
    "    print(\"--------------------------\")\n",
    "    print(str(node.text))\n",
    "    print(\"--------------------------\")\n",
    "print(\"\\nAnswer:\")\n",
    "print(str(response))\n",
    "print(\"\\nExpected Answer:\")\n",
    "print(expected_answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85f4e23b-0778-45b0-a38b-b91b4e59bc9b",
   "metadata": {},
   "source": [
    "## Evaluation of RAGs using Ragas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f031c8c-62c0-4a59-a724-16ced4263b17",
   "metadata": {},
   "source": [
    "So, for the question + documents + answers we have in our truncated dataset, let's calculate some metrics to help us improve the model.\n",
    "\n",
    "We'll use Ragas score. Let's benchmark whatevet model Llama Index is using by default."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba13fd6f-75df-42dd-9479-05d9f3812b04",
   "metadata": {},
   "source": [
    "## Ragas \n",
    "You need the following columns for Ragas Evaluation\n",
    "- question: list[str] - These are the questions your RAG pipeline will be evaluated on.\n",
    "- answer: list[str] - The answer generated from the RAG pipeline and given to the user.\n",
    "- contexts: list[list[str]] - The contexts that were passed into the LLM to answer the question.\n",
    "- ground_truths: list[list[str]] - The ground truth answer to the questions. (only required if you are using context_recall)\n",
    "\n",
    "\n",
    "## Ragas Metrics:\n",
    "The harmonic mean of these 4 aspects gives you the ragas score which is a single measure of the performance of your QA system across all the important aspects.\n",
    "- faithfulness - the factual consistency of the answer to the context base on the question.\n",
    "- context_precision - a measure of how relevant the retrieved context is to the question. Conveys quality of the retrieval pipeline.\n",
    "- answer_relevancy - a measure of how relevant the answer is to the question\n",
    "- context_recall: measures the ability of the retriever to retrieve all the necessary information needed to answer the question."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cc4d7273-775d-4345-aa4b-25fdb080565b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index import ServiceContext\n",
    "from llama_index.llms import OpenAI\n",
    "from ragas.metrics import (\n",
    "    answer_relevancy,\n",
    "    context_precision,\n",
    "    context_recall,\n",
    "    faithfulness,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fb27b941602401d91542211134fc71a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "91c9a585-4337-47c9-923e-491a9949f424",
   "metadata": {},
   "outputs": [],
   "source": [
    "from statistics import harmonic_mean\n",
    "\n",
    "import nest_asyncio\n",
    "from datasets import Dataset\n",
    "from llama_index.embeddings import OpenAIEmbedding\n",
    "from ragas import evaluate\n",
    "from tqdm import tqdm\n",
    "\n",
    "nest_asyncio.apply()\n",
    "\n",
    "\n",
    "def run_eval(embed_model=None, llm_model=None, dimensions=None):\n",
    "    questions = []\n",
    "    answers = []\n",
    "    contexts = []\n",
    "    ground_truths = []\n",
    "\n",
    "    if embed_model:\n",
    "        if dimensions:\n",
    "            embedding_model = OpenAIEmbedding(model=embed_model, dimensions=dimensions)\n",
    "        else:\n",
    "            embedding_model = OpenAIEmbedding(model=embed_model)\n",
    "        if llm_model:\n",
    "            the_service_context = ServiceContext.from_defaults(embed_model=embedding_model, llm=OpenAI(model=llm_model))\n",
    "        else:\n",
    "            the_service_context = ServiceContext.from_defaults(embed_model=embedding_model, llm=OpenAI())\n",
    "    else:\n",
    "        if llm_model:\n",
    "            the_service_context = ServiceContext.from_defaults(llm=OpenAI(model=llm_model))\n",
    "        else:\n",
    "            the_service_context = ServiceContext.from_defaults(llm=OpenAI())\n",
    "\n",
    "    documents = SimpleDirectoryReader(input_files=input_files).load_data(\"*.txt\")\n",
    "    index = VectorStoreIndex.from_documents(documents, service_context=the_service_context)\n",
    "    query_engine = index.as_query_engine()\n",
    "\n",
    "    for index in tqdm(range(0, len(input_files))):\n",
    "        row = dataset[\"train\"][index]\n",
    "        # The Question\n",
    "        question = row[\"question\"]\n",
    "        questions.append(question)\n",
    "\n",
    "        # The Answer\n",
    "        response = query_engine.query(question)\n",
    "        answer = str(response)\n",
    "        answers.append(answer)\n",
    "\n",
    "        # Contexts\n",
    "        context = []\n",
    "        for node in response.source_nodes:\n",
    "            context.append(str(node.text))\n",
    "        contexts.append(context)\n",
    "\n",
    "        # Ground Truth\n",
    "        actual_answer = row[\"answer\"]\n",
    "        ground_truths.append([actual_answer])\n",
    "\n",
    "    eval_dataset = Dataset.from_dict(\n",
    "        {\"question\": questions, \"contexts\": contexts, \"answer\": answers, \"ground_truths\": ground_truths}\n",
    "    )\n",
    "\n",
    "    result = evaluate(\n",
    "        eval_dataset,\n",
    "        metrics=[\n",
    "            context_precision,\n",
    "            faithfulness,\n",
    "            answer_relevancy,\n",
    "            context_recall,\n",
    "        ],\n",
    "    )\n",
    "    baseline_ragas = result\n",
    "    ragas_score = harmonic_mean(list(result.values()))\n",
    "\n",
    "    return baseline_ragas, ragas_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fc859626-c0d7-410d-9379-e0fa75e94580",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading files: 100%|██████████| 100/100 [00:00<00:00, 1659.75file/s]\n",
      "100%|██████████| 100/100 [04:10<00:00,  2.50s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluating with [context_precision]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [00:14<00:00,  2.04s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluating with [faithfulness]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [00:26<00:00,  3.81s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluating with [answer_relevancy]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [00:42<00:00,  6.05s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluating with [context_recall]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [00:18<00:00,  2.71s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Ragas Scores: {'context_precision': 0.7900, 'faithfulness': 0.9083, 'answer_relevancy': 0.9067, 'context_recall': 0.9225}\n",
      "Baseline Overall Ragas Scores: 0.8784084064903125\n"
     ]
    }
   ],
   "source": [
    "baseline_ragas, baseline_score = run_eval(embed_model=\"text-embedding-ada-002\", llm_model=\"gpt-3.5-turbo\")\n",
    "print(\"Baseline Ragas Scores:\", baseline_ragas)\n",
    "print(\"Baseline Overall Ragas Scores:\", baseline_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8bbbd55b-1094-4012-b8b5-b78f639660eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading files:   0%|          | 0/100 [00:00<?, ?file/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading files: 100%|██████████| 100/100 [00:00<00:00, 1062.56file/s]\n",
      "100%|██████████| 100/100 [03:22<00:00,  2.03s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluating with [context_precision]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [00:14<00:00,  2.04s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluating with [faithfulness]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [00:26<00:00,  3.85s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluating with [answer_relevancy]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [00:37<00:00,  5.42s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluating with [context_recall]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [00:20<00:00,  2.93s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text Embedding 3 small + GPT 3.5 Turbo Small Ragas Score: {'context_precision': 0.8000, 'faithfulness': 0.9117, 'answer_relevancy': 0.9084, 'context_recall': 0.9463}\n",
      "Text Embedding 3 small + GPT 3.5 Turbo Overall Ragas Score: 0.888005528949841\n"
     ]
    }
   ],
   "source": [
    "small_35t_ragas, small_35t_score = run_eval(embed_model=\"text-embedding-3-small\", llm_model=\"gpt-3.5-turbo\")\n",
    "print(\"Text Embedding 3 small + GPT 3.5 Turbo Small Ragas Score:\", small_35t_ragas)\n",
    "print(\"Text Embedding 3 small + GPT 3.5 Turbo Overall Ragas Score:\", small_35t_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ba41066a-9215-4498-a42c-4927ae457936",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading files: 100%|██████████| 100/100 [00:00<00:00, 2068.42file/s]\n",
      "100%|██████████| 100/100 [04:57<00:00,  2.98s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluating with [context_precision]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [00:12<00:00,  1.82s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluating with [faithfulness]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [00:32<00:00,  4.70s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluating with [answer_relevancy]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [00:52<00:00,  7.57s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluating with [context_recall]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [00:19<00:00,  2.85s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text Embedding 3 Large Ragas Score: {'context_precision': 0.8000, 'faithfulness': 0.9117, 'answer_relevancy': 0.9095, 'context_recall': 0.9258}\n",
      "Text Embedding 3 Large Overall Ragas Score: 0.883677716654227\n"
     ]
    }
   ],
   "source": [
    "large_35t_ragas, large_35t_score = run_eval(embed_model=\"text-embedding-3-large\", llm_model=\"gpt-3.5-turbo\")\n",
    "print(\"Text Embedding 3 Large Ragas Score:\", large_35t_ragas)\n",
    "print(\"Text Embedding 3 Large Overall Ragas Score:\", large_35t_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "25641cd4-dae7-470e-9124-d9cdff07f75c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading files: 100%|██████████| 100/100 [00:00<00:00, 2311.17file/s]\n",
      "100%|██████████| 100/100 [03:52<00:00,  2.32s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluating with [context_precision]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [00:13<00:00,  1.89s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluating with [faithfulness]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [00:37<00:00,  5.40s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluating with [answer_relevancy]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [00:36<00:00,  5.24s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluating with [context_recall]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [00:18<00:00,  2.69s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text Embedding 3 + GPT 4 Ragas Score: {'context_precision': 0.8000, 'faithfulness': 0.9080, 'answer_relevancy': 0.8718, 'context_recall': 0.9450}\n",
      "Text Embedding 3 + GPT 4 Overall Ragas Score: 0.8778556070635826\n"
     ]
    }
   ],
   "source": [
    "small_4_ragas, small_4_score = run_eval(embed_model=\"text-embedding-3-small\", llm_model=\"gpt-4\")\n",
    "print(\"Text Embedding 3 + GPT 4 Ragas Score:\", small_4_ragas)\n",
    "print(\"Text Embedding 3 + GPT 4 Overall Ragas Score:\", small_4_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "04fa1321-4da1-499c-afb8-61db1aa9f7c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading files: 100%|██████████| 100/100 [00:00<00:00, 2186.37file/s]\n",
      "100%|██████████| 100/100 [03:41<00:00,  2.21s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluating with [context_precision]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [00:12<00:00,  1.76s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluating with [faithfulness]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [00:34<00:00,  4.88s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluating with [answer_relevancy]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [00:40<00:00,  5.86s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluating with [context_recall]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [00:21<00:00,  3.03s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text Embedding 3 + GPT 4 Turbo Small Ragas Score: {'context_precision': 0.7800, 'faithfulness': 0.8960, 'answer_relevancy': 0.9107, 'context_recall': 0.9311}\n",
      "Text Embedding 3 + GPT 4 Turbo Ragas Score: 0.8752526577076438\n"
     ]
    }
   ],
   "source": [
    "small_4t_ragas, small_4t_score = run_eval(embed_model=\"text-embedding-3-small\", llm_model=\"gpt-4-turbo-preview\")\n",
    "print(\"Text Embedding 3 + GPT 4 Turbo Small Ragas Score:\", small_4t_ragas)\n",
    "print(\"Text Embedding 3 + GPT 4 Turbo Ragas Score:\", small_4t_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "671ac9e5-b278-4b0d-ba18-2b08e1727475",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading files: 100%|██████████| 100/100 [00:00<00:00, 2331.22file/s]\n",
      "100%|██████████| 100/100 [03:56<00:00,  2.37s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluating with [context_precision]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [00:12<00:00,  1.74s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluating with [faithfulness]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [00:35<00:00,  5.11s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluating with [answer_relevancy]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [00:37<00:00,  5.41s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluating with [context_recall]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [00:20<00:00,  2.94s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text Embedding 3 Large + GPT 4 Turbo Small Ragas Score: {'context_precision': 0.8000, 'faithfulness': 0.9030, 'answer_relevancy': 0.9130, 'context_recall': 0.9071}\n",
      "Text Embedding 3 Large + GPT 4 Turbo Ragas Score: 0.8781295283806929\n"
     ]
    }
   ],
   "source": [
    "large_4t_ragas, large_4t_score = run_eval(embed_model=\"text-embedding-3-large\", llm_model=\"gpt-4-turbo-preview\")\n",
    "print(\"Text Embedding 3 Large + GPT 4 Turbo Small Ragas Score:\", large_4t_ragas)\n",
    "print(\"Text Embedding 3 Large + GPT 4 Turbo Ragas Score:\", large_4t_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "72d49841-eeeb-4115-83ac-5f5587328208",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading files:   0%|          | 0/100 [00:00<?, ?file/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading files: 100%|██████████| 100/100 [00:00<00:00, 1701.00file/s]\n",
      "100%|██████████| 100/100 [05:15<00:00,  3.16s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluating with [context_precision]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [00:11<00:00,  1.66s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluating with [faithfulness]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [00:37<00:00,  5.34s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluating with [answer_relevancy]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [00:35<00:00,  5.02s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluating with [context_recall]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [00:24<00:00,  3.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text Embedding 3 Large (256) + GPT 4 Turbo Small Ragas Score: {'context_precision': 0.7850, 'faithfulness': 0.8993, 'answer_relevancy': 0.9123, 'context_recall': 0.9444}\n",
      "Text Embedding 3 Large (256) + GPT 4 Turbo Ragas Score: 0.8809172569758493\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "large_256_4t_ragas, large_256_4t_score = run_eval(\n",
    "    embed_model=\"text-embedding-3-small\", dimensions=256, llm_model=\"gpt-4-turbo-preview\"\n",
    ")\n",
    "print(\"Text Embedding 3 Large (256) + GPT 4 Turbo Small Ragas Score:\", large_256_4t_ragas)\n",
    "print(\"Text Embedding 3 Large (256) + GPT 4 Turbo Ragas Score:\", large_256_4t_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "565a43d0-1064-4b19-94e3-0b0d821a36da",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd9ceefc-f3d6-424a-a5a4-e995c4208be7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Embedding Model</th>\n",
       "      <th>LLM Model</th>\n",
       "      <th>Ragas Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>text-embedding-ada-002</td>\n",
       "      <td>gpt-3.5-turbo</td>\n",
       "      <td>0.915011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>text-embedding-3-small</td>\n",
       "      <td>gpt-3.5-turbo</td>\n",
       "      <td>0.916095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>text-embedding-3-large</td>\n",
       "      <td>gpt-3.5-turbo</td>\n",
       "      <td>0.915233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>text-embedding-3-small</td>\n",
       "      <td>gpt-4</td>\n",
       "      <td>0.922723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>text-embedding-3-small</td>\n",
       "      <td>gpt-4-turbo-preview</td>\n",
       "      <td>0.920660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>text-embedding-3-large</td>\n",
       "      <td>gpt-4-turbo-preview</td>\n",
       "      <td>0.915466</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Embedding Model            LLM Model  Ragas Score\n",
       "0  text-embedding-ada-002        gpt-3.5-turbo     0.915011\n",
       "1  text-embedding-3-small        gpt-3.5-turbo     0.916095\n",
       "2  text-embedding-3-large        gpt-3.5-turbo     0.915233\n",
       "3  text-embedding-3-small                gpt-4     0.922723\n",
       "4  text-embedding-3-small  gpt-4-turbo-preview     0.920660\n",
       "5  text-embedding-3-large  gpt-4-turbo-preview     0.915466"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comparison = {\n",
    "    \"Embedding Model\": [\n",
    "        \"text-embedding-ada-002\",\n",
    "        \"text-embedding-3-small\",\n",
    "        \"text-embedding-3-large\",\n",
    "        \"text-embedding-3-small\",\n",
    "        \"text-embedding-3-small\",\n",
    "        \"text-embedding-3-large\",\n",
    "    ],\n",
    "    \"LLM Model\": [\n",
    "        \"gpt-3.5-turbo\",\n",
    "        \"gpt-3.5-turbo\",\n",
    "        \"gpt-3.5-turbo\",\n",
    "        \"gpt-4\",\n",
    "        \"gpt-4-turbo-preview\",\n",
    "        \"gpt-4-turbo-preview\",\n",
    "    ],\n",
    "    \"Ragas Score\": [baseline_score, small_35t_score, large_35t_score, small_4_score, small_4t_score, large_4t_score],\n",
    "}\n",
    "df = pd.DataFrame.from_dict(comparison)\n",
    "df.head(n=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "251e0246",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.1.1'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75a08071",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2acfd6da",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
